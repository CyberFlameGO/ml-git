{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a basic flow of ml-git with api. There you will learn how to initialize an ml-git project, how to perform all necessary configuration steps and how to version a dataset. We will divide this quick howto into 3 main sections:\n",
    "\n",
    "##### ml-git repository configuation/intialization \n",
    "     This section explains how to initialize and configure a repository for ml-git. \n",
    "##### versioning a dataset\n",
    "    Having a repository initialized, this section explains how to create and upload a dataset to the store. \n",
    "##### downloading a dataset\n",
    "    This section describes how to download a versioned data set using ml-git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - ml-git repository configuation/intialization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start using the ml-git api we need to import it into our script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_git import api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use ml-git, it is necessary to configure storages and remotes that will be used in a project. This configuration can be done through a sequence of commands, or if you already have a git repository with the stored settings, you can run the clone command to import those settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will consider the scenario of a user who wants to configure their project from scratch. The first step is to define that the directory we are working on will be an ml-git project, for this we execute the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api.init('repository')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing an ml-git project, it is necessary that you inform the remotes and storages that will be used by the entities to be versioned. If you want to better understand why ml-git uses these resources, please take a look at the [architecture and internals documentation](../../mlgit_internals.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will configure our ml-git project with a local git repository and a local minio as storage. For this, the following commands are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "remote_url = '/local_server.git/'\n",
    "bucket_name= 'mlgit'\n",
    "end_point = 'http://127.0.0.1:9000'\n",
    "\n",
    "# The type of entity we are working on\n",
    "entity_type = 'dataset'\n",
    "\n",
    "api.remote_add(entity_type, remote_url)\n",
    "api.store_add(bucket_name, endpoint_url=end_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, initialize the metadata repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api.init(entity_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - versioning a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the entities have been initialized and are ready for use. We can continue with the process to version our first dataset.\n",
    "\n",
    "ml-git expects any dataset to be specified under *dataset/* directory of your project and it expects a specification file with the name of the dataset.\n",
    "\n",
    "To create this specification file for a new entity you must run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The entity name we are working on\n",
    "entity_name = 'dataset-ex'\n",
    "\n",
    "api.create(entity_type, entity_name, categories=['computer-vision', 'images'], mutability='strict', bucket_name=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we create our dataset entity we can add the data to be versioned within the entity's directory. For this, the following code generate a new file in our dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_file(file_name='file'):\n",
    "    file_path = os.path.join('dataset', 'dataset-ex', 'data', file_name)\n",
    "    open(file_path, 'a').close()\n",
    "\n",
    "create_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed with the necessary steps to send the new data to storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.add(entity_type, entity_name, bumpversion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After add the files, you need commit the metadata to the local repository. For this purpose type the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom commit message\n",
    "message = 'Commit example'\n",
    "\n",
    "api.commit(entity_type, entity_name, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, ml-git dataset push will update the remote metadata repository just after storing all actual data under management in the specified remote data store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.push(entity_type, entity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, ml-git follows very similar workflows as for git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - downloading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have an entity versioned by ml-git, and being within an initialized directory, it is really simple to obtain data from a specific entity. As an example, in this notebook we will checkout an entity that was previously versioned, the mnist. For this, the following command is necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_name = 'mnist'\n",
    "\n",
    "data_path = api.checkout(entity_type, entity_name, version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data will auto-create a directory structure under dataset directory. That structure *computer-vision/images* is actually coming from the categories defined in the dataset spec file. Doing that way allows for easy download of many datasets in one single ml-git project without creating any conflicts.\n",
    "\n",
    "Now the user can perform the processes he wants with the data that was downloaded in the workspace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}